# ERA - Excellent Reasoning Architecture

**A sovereign decision governance system with ministerial councils, ML wisdom, and interactive dialogue engines.**

---

## ğŸš€ Quick Start

### Installation (5 minutes)

```bash
# 1. Clone or navigate to ERA directory
cd c:\era

# 2. (Optional) Create virtual environment
python -m venv .venv
.\.venv\Scripts\Activate.ps1

# 3. Install dependencies
pip install -r requirements.txt

# 4. Start Ollama (separate terminal)
ollama serve

# 5. Pull LLM models (one-time)
ollama pull deepseek-r1:8b
ollama pull qwen3:14b
```

### Run ERA (Choose Your Path)

**Path 1: LLM Dialogue Engine** (Easiest - 30 seconds)
```bash
python llm_conversation.py --mode demo --rounds 1
```

**Path 2: Decision Guidance System** (10-20 minutes)
```bash
python system_main.py
```

**Path 3: Multi-Session Problem Solving** (Variable)
```bash
python run_session_conversation.py
```

**Path 4: Ministerial Council Simulation** (Variable)
```bash
python sovereign_main.py
```

---

## ğŸ“š What is ERA?

ERA is a **Ministerial Cognitive Architecture (MCA)** that combines:

| Component | Purpose |
|-----------|---------|
| **Mode Orchestrator** | Routes decisions through 4 complexity levels (QUICK â†’ MEETING â†’ WAR â†’ DARBAR) |
| **19 Ministers** | Domain-bounded advisors giving perspectives (Risk, Data, Diplomacy, etc.) |
| **KIS Engine** | Knowledge Integration System scoring knowledge across 5 factors |
| **ML Wisdom** | Learns from episodes to improve future decisions |
| **LLM Integration** | Direct dialogue with deepseek-r1:8b and qwen3:14b models |
| **Session Management** | Multi-turn problem solving with automatic escalation |

---

## ğŸ¯ Core Features

### âœ… 1. LLM Conversation Engine
- Interactive (choose any topic)
- Demo mode (pre-built conversations)
- Topic mode (specify custom topics)
- Full persistence (JSON transcripts)

### âœ… 2. Decision Guidance System  
- 9-phase dialogue pipeline
- Auto-domain detection (15 domains)
- 3 rounds of clarifying questions
- Council of relevant ministers
- Prime Confident final decision authority
- User feedback loop
- Satisfaction assessment

### âœ… 3. Session-Based Problem Solving
- Multi-session continuity
- Auto-mode escalation (QUICK â†’ DARBAR)
- Consequence tracking
- Related session discovery
- Session statistics

### âœ… 4. Ministerial Council
- 19 domain specialists
- Mode-specific voting (QUICK/MEETING/WAR/DARBAR)
- KIS-driven recommendations
- Judge observing outcomes

### âœ… 5. Machine Learning Wisdom
- Judgment priors from past decisions
- Feature extraction from decision state
- KIS scoring (5-factor: domain Ã— type Ã— memory Ã— context Ã— goal)
- Episodic memory persistence

### âœ… 6. System Simulation
- Synthetic human generation
- Multi-agent scenarios
- Crisis simulation
- Population dynamics

---

## ğŸ“ Project Structure

```
C:\era\
â”œâ”€â”€ llm_conversation.py           # LLM dialogue engine
â”œâ”€â”€ system_main.py                # Decision guidance system  
â”œâ”€â”€ run_session_conversation.py    # Session-based problem solving
â”œâ”€â”€ sovereign_main.py              # Ministerial council simulation
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ START_HERE.md                  # Installation guide
â”œâ”€â”€ README.md                      # This file
â”œâ”€â”€ CHANGELOG.md                   # Version history
â”œâ”€â”€ DEPENDENCIES.md                # System requirements
â”‚
â”œâ”€â”€ persona/                       # Interactive persona system
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ modes/                     # Mode orchestration
â”‚   â”œâ”€â”€ ministers/                 # Individual minister implementations
â”‚   â”œâ”€â”€ knowledge_engine.py        # KIS (Knowledge Integration System)
â”‚   â”œâ”€â”€ domain_detector.py         # Auto-detect problem domains
â”‚   â”œâ”€â”€ session_manager.py         # Session lifecycle management
â”‚   â”œâ”€â”€ cache_manager.py           # Automatic cache cleanup
â”‚   â””â”€â”€ ... (15+ submodules)
â”‚
â”œâ”€â”€ sovereign/                     # Ministerial council system
â”‚   â”œâ”€â”€ ministers/                 # 19 domain specialists
â”‚   â”œâ”€â”€ dynamic_council.py         # Council selection logic
â”‚   â”œâ”€â”€ prime_confident.py         # Decision authority
â”‚   â””â”€â”€ minister_factory.py        # Minister instantiation
â”‚
â”œâ”€â”€ ml/                            # Machine learning wisdom layer
â”‚   â”œâ”€â”€ llm_handshakes/            # LLM interface (structured calls)
â”‚   â”œâ”€â”€ kis/                       # Knowledge Integration System
â”‚   â”œâ”€â”€ judgment_priors.py         # ML judgment learning
â”‚   â”œâ”€â”€ ml_orchestrator.py         # ML pipeline
â”‚   â””â”€â”€ ... (learning components)
â”‚
â”œâ”€â”€ hse/                           # Human Simulation Engine
â”‚   â”œâ”€â”€ population_manager.py      # Synthetic human generation
â”‚   â”œâ”€â”€ human_profile.py           # Individual profiles
â”‚   â”œâ”€â”€ crisis_injector.py         # Stress/crisis scenarios
â”‚   â””â”€â”€ analytics_server.py        # Performance tracking
â”‚
â”œâ”€â”€ ingestion/                     # Knowledge ingestion pipeline
â”‚   â”œâ”€â”€ v2/                        # Async ingestion pipeline
â”‚   â”‚   â””â”€â”€ run_all_v2_ingest.py   # Process PDFs to embeddings
â”‚   â””â”€â”€ ... (v1 legacy)
â”‚
â”œâ”€â”€ data/                          # All data storage
â”‚   â”œâ”€â”€ doctrine/                  # Minister decision rules (YAML)
â”‚   â”œâ”€â”€ books/                     # Ingested knowledge (61 PDFs)
â”‚   â”œâ”€â”€ sessions/                  # Session records
â”‚   â”œâ”€â”€ conversations/             # LLM dialogue transcripts
â”‚   â”œâ”€â”€ memory/                    # Episodic learning storage
â”‚   â””â”€â”€ ... (RAG, memory, etc.)
â”‚
â”œâ”€â”€ tests/                         # Test suite (27 test files)
â”œâ”€â”€ documentation/                 # 50+ comprehensive guides
â”œâ”€â”€ archive/                       # Deprecated modules
â”‚   â”œâ”€â”€ integrations_old/          # (Archived: unused)
â”‚   â””â”€â”€ runtime_old/               # (Archived: experimental)
â””â”€â”€ logs/                          # Runtime logs
```

---

## ğŸ”§ Configuration

### Environment Variables (.env)

Create `.env` file in `C:\era\`:

```env
# Ollama Configuration
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL_USER=deepseek-r1:8b
OLLAMA_MODEL_PROGRAM=qwen3:14b
OLLAMA_TIMEOUT=300

# System Paths
ERA_ROOT=c:\era
DATA_ROOT=c:\era\data

# Logging
LOG_LEVEL=INFO

# ML Configuration
ML_BATCH_SIZE=32
ML_LEARNING_RATE=0.001
```

See `.env.example` for all options.

---

## ğŸ“– Documentation

### Getting Started
- **[START_HERE.md](START_HERE.md)** - Installation & quick start (5 min)
- **[DEPENDENCIES.md](DEPENDENCIES.md)** - System requirements (2 min)

### Understanding the System
- **[SYSTEM_ARCHITECTURE.md](documentation/SYSTEM_ARCHITECTURE.md)** - Full architecture (20 min)
- **[MODE_SELECTION_GUIDE.md](documentation/MODE_SELECTION_GUIDE.md)** - When to use which mode (5 min)
- **[SESSION_FEATURES_GUIDE.md](documentation/SESSION_FEATURES_GUIDE.md)** - Multi-session workflows (10 min)

### Reference
- **[CHANGELOG.md](CHANGELOG.md)** - Version history
- **[DEAD_ENDS_RESOLUTION.md](DEAD_ENDS_RESOLUTION.md)** - Cleanup decisions
- **[documentation/](documentation/)** - 50+ comprehensive guides

---

## ğŸ“ Learning Paths

### For New Users (30 minutes)
1. Read [START_HERE.md](START_HERE.md)
2. Install dependencies
3. Run: `python llm_conversation.py --mode demo --rounds 1`

### For Decision Makers (1-2 hours)
1. Read [MODE_SELECTION_GUIDE.md](documentation/MODE_SELECTION_GUIDE.md)
2. Run: `python system_main.py`
3. Try different scenarios

### For Developers (2-4 hours)
1. Read [SYSTEM_ARCHITECTURE.md](documentation/SYSTEM_ARCHITECTURE.md)
2. Study `persona/`, `sovereign/`, `ml/` modules
3. Review test suite in `tests/`

### For System Administrators
1. Check [DEPENDENCIES.md](DEPENDENCIES.md)
2. Run: `python persona/cache_manager.py`
3. Monitor logs in `logs/`

---

## ğŸš€ Common Workflows

### Workflow 1: Quick LLM Dialogue
```bash
python llm_conversation.py --mode demo --rounds 2
```
â±ï¸ **Time:** 1-2 minutes | ğŸ’¬ **Output:** Conversation transcript

### Workflow 2: Get Decision Guidance
```bash
python system_main.py
```
â±ï¸ **Time:** 10-20 minutes | ğŸ“‹ **Output:** 9-phase guidance with council input

### Workflow 3: Multi-Session Problem Solving
```bash
python run_session_conversation.py
```
â±ï¸ **Time:** Variable | ğŸ”„ **Output:** Multiple sessions with continuity

### Workflow 4: Run Ministerial Simulation
```bash
python sovereign_main.py
```
â±ï¸ **Time:** Variable | ğŸ­ **Output:** Full council voting & outcomes

### Workflow 5: Cleanup Cache
```bash
python persona/cache_manager.py
```
â±ï¸ **Time:** 1 second | ğŸ§¹ **Output:** Cache report & cleanup

---

## âš™ï¸ System Requirements

| Component | Minimum | Recommended |
|-----------|---------|-------------|
| **CPU** | 4 cores | 8+ cores |
| **RAM** | 4 GB | 8+ GB |
| **Disk** | 5 GB | 10+ GB |
| **Python** | 3.10 | 3.12+ |
| **Ollama** | Latest | Latest |

---

## ğŸ§  Decision Modes

| Mode | Use Case | Ministers | Speed |
|------|----------|-----------|-------|
| **QUICK** | Mentoring, direct advice | None (LLM only) | Fast |
| **MEETING** | Balanced perspective | 3-5 relevant | Medium |
| **WAR** | Victory-focused strategy | 5 specific | Medium |
| **DARBAR** | Full wisdom council | All 19 | Slow |

Auto-escalates: QUICK (1-2) â†’ MEETING (3-5) â†’ WAR (6-8) â†’ DARBAR (9+)

---

## ğŸ› ï¸ Troubleshooting

### "Ollama not running"
```bash
ollama serve  # In separate terminal
```

### "Module not found"
```bash
pip install -r requirements.txt
```

### "Connection refused"
```bash
# Check Ollama is running on port 11434
netstat -ano | findstr :11434
```

### Cache taking too much space
```bash
python persona/cache_manager.py
```

See [DEPENDENCIES.md](DEPENDENCIES.md) for more troubleshooting.

---

## ğŸ“Š System Status

**Last Updated:** February 19, 2026  
**Version:** 1.2.0  
**Status:** âœ… OPERATIONAL

All systems verified and tested:
- âœ… LLM integration (deepseek-r1:8b + qwen3:14b)
- âœ… Decision guidance (9-phase pipeline)
- âœ… Ministerial councils (19 ministers)
- âœ… ML learning (judgment priors)
- âœ… Session management (multi-turn)
- âœ… Cache cleanup (automatic)
- âœ… Documentation (50+ guides)

---

## ğŸ¤ Contributing

### Reporting Issues
Use [DEAD_ENDS_RESOLUTION.md](DEAD_ENDS_RESOLUTION.md) format for cleanup issues.

### Code Changes
1. Create feature branch
2. Update relevant tests
3. Run: `pytest tests/ -v`
4. Update documentation

---

## ğŸ“œ License & Attribution

**Creator:** Alfred (Stabilizing Intelligence)  
**Project Motto:** "Power that costs identity is rejected."  
**License:** Internal use (Detailed terms in LICENSE if applicable)

---

## ğŸ”— Quick Links

| What | Where |
|------|-------|
| Installation | [START_HERE.md](START_HERE.md) |
| Architecture | [documentation/SYSTEM_ARCHITECTURE.md](documentation/SYSTEM_ARCHITECTURE.md) |
| Mode Guide | [documentation/MODE_SELECTION_GUIDE.md](documentation/MODE_SELECTION_GUIDE.md) |
| Sessions | [documentation/SESSION_FEATURES_GUIDE.md](documentation/SESSION_FEATURES_GUIDE.md) |
| Requirements | [DEPENDENCIES.md](DEPENDENCIES.md) |
| Changes | [CHANGELOG.md](CHANGELOG.md) |
| Cleanup | [DEAD_ENDS_RESOLUTION.md](DEAD_ENDS_RESOLUTION.md) |

---

**Status:** âœ… Ready to Use  
**Next Step:** Read [START_HERE.md](START_HERE.md)  
**Questions?** Check [documentation/](documentation/) folder (50+ guides)
