# 02_ARCHITECTURE.md

# ğŸ—ï¸ Era Project - System Architecture

**Complete architectural overview with component diagrams and integration points**

---

## High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           ERA / PERSONA N                                â”‚
â”‚                  Ministerial Cognitive Architecture                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                           â”‚                           â”‚
        â–¼                           â–¼                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PERSONA LAYER   â”‚    â”‚   ML LAYER       â”‚    â”‚   HSE LAYER      â”‚
â”‚  (Decision Core) â”‚    â”‚ (Learning/ML)    â”‚    â”‚ (Simulation)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                           â”‚                           â”‚
        â”œâ”€ Mode Orchestrator        â”œâ”€ KIS Engine               â”œâ”€ Synthetic Human
        â”œâ”€ Ministerial Council      â”œâ”€ Feature Extraction       â”œâ”€ Stress Injector
        â”œâ”€ Prime Confident          â”œâ”€ Judgment Priors          â”œâ”€ Personality Drift
        â”œâ”€ Episodic Memory          â”œâ”€ Pattern Extraction       â””â”€ Population Mgr
        â””â”€ Performance Metrics      â””â”€ Sovereign Orchestrator
```

---

## Layer 1: Persona Core

### Purpose
Generate wise, context-aware decisions using ministerial council and mode-based reasoning.

### Components

```
persona/
â”œâ”€â”€ main.py                      # Entry point, conversation loop
â”œâ”€â”€ brain.py                     # High-level decision control
â”œâ”€â”€ ollama_runtime.py            # LLM connection layer
â”œâ”€â”€ context.py                   # Conversation context management
â”œâ”€â”€ state.py                     # System state tracking
â”œâ”€â”€ trace.py                     # Debug tracing
â”‚
â”œâ”€â”€ council/
â”‚   â”œâ”€â”€ dynamic_council.py       # Mode-aware minister selection
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ modes/
â”‚   â”œâ”€â”€ mode_orchestrator.py     # 4-mode routing logic
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ [mode strategies]
â”‚
â”œâ”€â”€ learning/
â”‚   â”œâ”€â”€ episodic_memory.py       # Turn-by-turn storage
â”‚   â”œâ”€â”€ performance_metrics.py   # Success rate tracking
â”‚   â”œâ”€â”€ consequence_engine.py    # Forward simulation
â”‚   â”œâ”€â”€ confidence_model.py      # Bayesian confidence
â”‚   â”œâ”€â”€ outcome_feedback_loop.py # Outcome â†’ adjustment
â”‚   â””â”€â”€ failure_analysis.py      # Root cause diagnosis
â”‚
â”œâ”€â”€ validation/
â”‚   â”œâ”€â”€ mode_validator.py        # Mode consistency checks
â”‚   â””â”€â”€ identity_validator.py    # Self-contradiction detection
â”‚
â”œâ”€â”€ persistence/
â”‚   â””â”€â”€ conversation_arc.py      # Long-term narrative tracking
â”‚
â””â”€â”€ pwm_integration/
    â””â”€â”€ pwm_bridge.py            # Personal World Model sync
```

### Data Flow

```
User Input
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Mode Check     â”‚ â† Is this a /mode command?
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Get Current Modeâ”‚ â† QUICK/WAR/MEETING/DARBAR
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Mode Orchestrator Routes Decision â”‚
â”‚   â”œâ”€ Should invoke council?         â”‚
â”‚   â”œâ”€ Which ministers?               â”‚
â”‚   â”œâ”€ How to frame?                  â”‚
â”‚   â””â”€ How to aggregate?              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚         â”‚
    â–¼         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  QUICK  â”‚ â”‚ WAR/MEETING/DARBAR   â”‚
â”‚  Mode   â”‚ â”‚ (Council Required)   â”‚
â”‚         â”‚ â”‚                      â”‚
â”‚ Direct  â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ LLM     â”‚ â”‚ â”‚ Dynamic Council  â”‚ â”‚
â”‚ Responseâ”‚ â”‚ â”‚ â”œâ”€ Select Mins   â”‚ â”‚
â”‚         â”‚ â”‚ â”‚ â”œâ”€ Convene       â”‚ â”‚
â”‚         â”‚ â”‚ â”‚ â”œâ”€ Aggregate     â”‚ â”‚
â”‚         â”‚ â”‚ â”‚ â””â”€ Prime Review  â”‚ â”‚
â”‚         â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                 â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ Store Episode  â”‚
     â”‚ Record Metrics â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ Display Responseâ”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Layer 2: ML Learning System

### Purpose
Learn from outcomes, extract patterns, and improve decision quality over time.

### Components

```
ml/
â”œâ”€â”€ sovereign_orchestrator.py    # 12-system integration hub
â”œâ”€â”€ ml_orchestrator.py           # ML wisdom pipeline
â”œâ”€â”€ system_retraining.py         # Minister retraining logic
â”œâ”€â”€ minister_retraining.py       # Per-minister updates
â”œâ”€â”€ pattern_extraction.py        # Failure cluster detection
â”œâ”€â”€ vector_memory.py             # Vector-based memory
â”œâ”€â”€ reward_shaping.py            # Outcome-based rewards
â”œâ”€â”€ doctrine_update.py           # Doctrine evolution
â”‚
â”œâ”€â”€ kis/                         # Knowledge Integration System
â”‚   â””â”€â”€ knowledge_integration_system.py
â”‚
â”œâ”€â”€ features/                    # Feature Extraction
â”‚   â””â”€â”€ feature_extractor.py
â”‚
â”œâ”€â”€ labels/                      # Label Generation
â”‚   â””â”€â”€ label_generator.py
â”‚
â”œâ”€â”€ judgment/                    # ML Judgment Priors
â”‚   â””â”€â”€ ml_judgment_prior.py
â”‚
â”œâ”€â”€ llm_handshakes/              # LLM Sensing Layer
â”‚   â””â”€â”€ llm_interface.py
â”‚
â”œâ”€â”€ models/                      # Trained Models
â”‚   â””â”€â”€ judgment_prior.json
â”‚
â””â”€â”€ cache/                       # Session Cache
    â””â”€â”€ session.json
```

### ML Pipeline

```
Decision Made
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM Handshakes (Sensing Layer)     â”‚
â”‚  â”œâ”€ Situation framing               â”‚
â”‚  â”œâ”€ Constraint extraction           â”‚
â”‚  â”œâ”€ Counterfactual generation       â”‚
â”‚  â””â”€ Intent detection                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Feature Extraction                 â”‚
â”‚  Convert situation â†’ 41-dim vector  â”‚
â”‚  â”œâ”€ Situation features (14)         â”‚
â”‚  â”œâ”€ Constraint features (6)         â”‚
â”‚  â”œâ”€ Knowledge features (14)         â”‚
â”‚  â””â”€ Action features (7)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  KIS (Knowledge Integration System) â”‚
â”‚  Rank knowledge by 5 factors:       â”‚
â”‚  â”œâ”€ Domain weight (0.25-1.4)        â”‚
â”‚  â”œâ”€ Type weight (0.9-1.1)           â”‚
â”‚  â”œâ”€ Memory weight (1.0-8.0)         â”‚
â”‚  â”œâ”€ Context weight (0.85-1.4)       â”‚
â”‚  â””â”€ Goal weight (0.7-1.2)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ML Judgment Prior                  â”‚
â”‚  Apply learned weights based on     â”‚
â”‚  similar past situations            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Outcome Recording                  â”‚
â”‚  Store success/failure, regret      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Label Generation                   â”‚
â”‚  Convert outcome â†’ training label   â”‚
â”‚  (adjust type weights)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Model Training (every 50 samples)  â”‚
â”‚  Update judgment prior model        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### KIS Weight Formula

```
KIS_score = domain_weight Ã— type_weight Ã— memory_weight Ã— context_weight Ã— goal_weight

Where:
- domain_weight: 0.25-1.4 (based on domain confidence)
- type_weight: 0.9-1.1 (principle=1.0, rule=1.1, advice=0.9)
- memory_weight: (1 + ln(1 + rc)) Ã— exp(-0.3 Ã— pc)
  - rc = reinforcement count
  - pc = penalty count
- context_weight: 0.85-1.4 (keyword matches)
- goal_weight: 0.7-1.2 (strategic language)
```

---

## Layer 3: Human Simulation Environment (HSE)

### Purpose
Provide realistic human simulation for testing, stress-testing, and validation.

### Components

```
hse/
â”œâ”€â”€ human_profile.py             # Synthetic human definition
â”œâ”€â”€ personality_drift.py         # Personality evolution
â”œâ”€â”€ crisis_injector.py           # Crisis scenario injection
â”œâ”€â”€ population_manager.py        # Multi-human management
â”œâ”€â”€ analytics_server.py          # Analytics API
â”‚
â””â”€â”€ simulation/
    â”œâ”€â”€ synthetic_human_sim.py   # Main simulation engine
    â”œâ”€â”€ human_persona_adapter.py # Human â†” Persona bridge
    â”œâ”€â”€ stress_orchestrator.py   # Stress scenario orchestration
    â””â”€â”€ bidirectional_simulation.py # Two-way conversation
```

### Simulation Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Synthetic Human Simulation Loop                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Generate Human  â”‚ â† LLM (llama3.1:8b)
â”‚ Input (Turn N)  â”‚   Based on personality + context
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Persona N       â”‚ â† Mode + Council + Ministers
â”‚ Generates       â”‚
â”‚ Response        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Record Episode  â”‚ â† Store to memory
â”‚ Record Metrics  â”‚ â† Update success rate
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Generate Human  â”‚ â† LLM reacts to response
â”‚ Input (Turn N+1)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â””â”€â”€â”€ Repeat for 100-1000 turns
```

### Stress Testing

```
Normal Operation
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Crisis Injector â”‚ â† Trigger at turn X
â”‚ (e.g., job loss,â”‚
â”‚  health crisis) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Personality     â”‚ â† Increase stress,
â”‚ Drift Engine    â”‚   change behavior
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Measure Persona â”‚ â† Trust, adoption,
â”‚ Response Qualityâ”‚   coherence under pressure
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Layer 4: Sovereign Integration

### Purpose
Integrate all 12 cognitive systems into a cohesive orchestration layer.

### The 12 Systems

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Sovereign Orchestrator                      â”‚
â”‚                                                              â”‚
â”‚  Learning & Memory (4 systems)                               â”‚
â”‚  â”œâ”€ 1. EpisodicMemory     â†’ Decision + outcome storage      â”‚
â”‚  â”œâ”€ 2. ConsequenceEngine  â†’ Forward ripple simulation       â”‚
â”‚  â”œâ”€ 3. BayesianConfidence â†’ Domain confidence tracking      â”‚
â”‚  â””â”€ 4. PerformanceMetrics â†’ Success rate aggregation        â”‚
â”‚                                                              â”‚
â”‚  Feedback & Improvement (2 systems)                          â”‚
â”‚  â”œâ”€ 5. OutcomeFeedbackLoop â†’ Outcomes â†’ minister updates    â”‚
â”‚  â””â”€ 6. SystemRetraining    â†’ Pattern extraction + doctrine  â”‚
â”‚                                                              â”‚
â”‚  Validation & Governance (3 systems)                         â”‚
â”‚  â”œâ”€ 7. ModeValidator       â†’ Mode consistency enforcement   â”‚
â”‚  â”œâ”€ 8. IdentityValidator   â†’ Self-contradiction detection   â”‚
â”‚  â””â”€ 9. ConversationArc     â†’ Long-term narrative tracking   â”‚
â”‚                                                              â”‚
â”‚  Character & Stress (3 systems)                              â”‚
â”‚  â”œâ”€ 10. SyntheticHuman     â†’ Persistent human character     â”‚
â”‚  â”œâ”€ 11. StressOrchestrator â†’ Compounding crisis chains      â”‚
â”‚  â””â”€ 12. HumanPersonaAdapter â†’ Trust/adoption measurement    â”‚
â”‚                                                              â”‚
â”‚  Reporting                                                   â”‚
â”‚  â””â”€ 13. PerformanceDashboard â†’ Real-time metrics + alerts   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4-Phase Progression

```
Phase 1: Infrastructure (Turns 0-100)
â”œâ”€ Initialize EpisodicMemory
â”œâ”€ Initialize PerformanceMetrics
â”œâ”€ Initialize SyntheticHuman
â””â”€ Record first 100 turns

Phase 2: Learning Loop (Turns 100-300)
â”œâ”€ Activate OutcomeFeedbackLoop
â”œâ”€ Activate ConversationArc
â”œâ”€ Activate IdentityValidator
â””â”€ Enable failure analysis

Phase 3: Optimization (Turns 300-700)
â”œâ”€ Activate ModeValidator
â”œâ”€ Activate FailureAnalysis
â”œâ”€ Trigger SystemRetraining (every 200 turns)
â””â”€ Extract success patterns

Phase 4: Stress Testing (Turns 700-1000+)
â”œâ”€ Activate StressScenarioOrchestrator
â”œâ”€ Measure stress response quality
â”œâ”€ Monitor trust trajectory
â””â”€ Generate dashboard reports
```

---

## Memory Architecture (Hybrid)

### Three-Tier Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    HYBRID MEMORY ARCHITECTURE                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Tier 1: EPISODIC MEMORY (Fast, Real-Time)
â”œâ”€ Update: Every turn
â”œâ”€ Stores: Decision, confidence, outcome, regret, consequences
â”œâ”€ Purpose: Pattern detection, mistake prevention
â”œâ”€ Format: JSONL files in Memory/
â””â”€ Query: find_similar_episodes(domain, pattern)

Tier 2: PERFORMANCE METRICS (Medium, Statistical)
â”œâ”€ Update: Every turn (recorded), every 100 turns (aggregated)
â”œâ”€ Stores: Success rates, minister performance, weak domains
â”œâ”€ Purpose: Identify weak features, guide retraining
â”œâ”€ Format: JSON (live_metrics.json)
â””â”€ Query: compute_domain_performance(), detect_weak_domains()

Tier 3: PWM - PERSONAL WORLD MODEL (Slow, Validated)
â”œâ”€ Update: Every 100 turns (after validation)
â”œâ”€ Stores: Validated facts about person/relationships
â”œâ”€ Purpose: Stable, high-confidence knowledge
â”œâ”€ Format: Entity-attribute graph
â””â”€ Query: query_entity(entity_id), generate_actionable_insights()

FLOW:
Every Turn â†’ Episodic + Metrics
Every 100 Turns â†’ Validate â†’ PWM Sync
Every 200 Turns â†’ Retrain with PWM insights
```

---

## Integration Points

### Between Layers

```
PERSONA LAYER â†â†’ ML LAYER
â”œâ”€ Episodic memory writes â†’ ML reads for patterns
â”œâ”€ Metrics aggregates â†’ ML uses for training
â”œâ”€ KIS rankings â†’ Persona uses for decisions
â””â”€ Retraining signals â†’ Persona updates ministers

PERSONA LAYER â†â†’ HSE LAYER
â”œâ”€ Synthetic human generates input â†’ Persona responds
â”œâ”€ Persona response â†’ Synthetic human reacts
â”œâ”€ Crisis injector â†’ Persona stress tests
â””â”€ Trust metrics â†’ Persona adaptation

ML LAYER â†â†’ HSE LAYER
â”œâ”€ Outcome data â†’ ML training labels
â”œâ”€ Pattern extraction â†’ Crisis scenario design
â””â”€ Performance metrics â†’ Simulation tuning
```

---

## File Dependencies

```
persona/main.py
â”œâ”€ imports: modes/mode_orchestrator.py
â”œâ”€ imports: council/dynamic_council.py
â”œâ”€ imports: learning/episodic_memory.py
â”œâ”€ imports: learning/performance_metrics.py
â”œâ”€ imports: ollama_runtime.py
â””â”€ imports: brain.py

ml/sovereign_orchestrator.py
â”œâ”€ imports: ../persona/learning/*
â”œâ”€ imports: ../persona/validation/*
â”œâ”€ imports: ../hse/simulation/*
â”œâ”€ imports: kis/knowledge_integration_system.py
â”œâ”€ imports: judgment/ml_judgment_prior.py
â””â”€ imports: features/feature_extractor.py

hse/simulation/synthetic_human_sim.py
â”œâ”€ imports: ../human_profile.py
â”œâ”€ imports: ../personality_drift.py
â”œâ”€ imports: ../../persona/ollama_runtime.py
â””â”€ imports: ../../ml/kis/*
```

---

## Runtime Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      RUNTIME FLOW                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. INITIALIZATION (Startup)
   â”œâ”€ Load environment (.env)
   â”œâ”€ Initialize OllamaRuntime (connect to Ollama)
   â”œâ”€ Load ministers (18 domain experts)
   â”œâ”€ Initialize ModeOrchestrator (4 modes)
   â”œâ”€ Initialize EpisodicMemory
   â”œâ”€ Initialize PerformanceMetrics
   â”œâ”€ Initialize SyntheticHuman (if automated)
   â””â”€ Display mode selection menu

2. MAIN LOOP (Per Turn)
   â”œâ”€ Get user input (or generate via synthetic human)
   â”œâ”€ Check for /mode command
   â”œâ”€ Route through ModeOrchestrator
   â”œâ”€ If QUICK: Direct LLM response
   â”œâ”€ If WAR/MEETING/DARBAR:
   â”‚   â”œâ”€ Select ministers (mode-dependent)
   â”‚   â”œâ”€ Convene council
   â”‚   â”œâ”€ Aggregate recommendations
   â”‚   â””â”€ Prime Confident review
   â”œâ”€ Store episode (episodic memory)
   â”œâ”€ Record metrics (performance tracking)
   â”œâ”€ Check for pattern extraction (every 100 turns)
   â””â”€ Display response

3. BACKGROUND (Asynchronous)
   â”œâ”€ Pattern extraction (every 100 turns)
   â”œâ”€ Minister retraining (every 200 turns)
   â”œâ”€ PWM sync (every 100 turns)
   â”œâ”€ Dashboard updates (every 10 turns)
   â””â”€ Failure analysis (on failures)

4. SHUTDOWN
   â”œâ”€ Save episodic memory
   â”œâ”€ Save metrics
   â”œâ”€ Save ML models
   â””â”€ Graceful thread pool shutdown
```

---

## Component Communication

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    COMMUNICATION PROTOCOLS                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

LLM Calls (Ollama)
â”œâ”€ Protocol: HTTP POST to localhost:11434/api/generate
â”œâ”€ Models: llama3.1:8b (user), qwen3:14b (persona)
â”œâ”€ Timeout: 30 seconds
â””â”€ Fallback: Graceful timeout response

Memory Storage
â”œâ”€ Format: JSONL (one episode per line)
â”œâ”€ Location: Memory/YYYY-MM-DD_episodes.jsonl
â”œâ”€ Sync: Immediate (every turn)
â””â”€ Backup: Manual (user-managed)

Metrics Storage
â”œâ”€ Format: JSON
â”œâ”€ Location: live_metrics.json
â”œâ”€ Sync: Every turn (in-memory), flush every 10 turns
â””â”€ Backup: Manual

ML Models
â”œâ”€ Format: JSON (judgment priors)
â”œâ”€ Location: ml/models/judgment_prior.json
â”œâ”€ Sync: Every 50 training samples
â””â”€ Backup: Manual
```

---

## Security & Safety

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      SAFETY MECHANISMS                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Red Lines (Protected by All Ministers)
â”œâ”€ âŒ No fraud/corruption (Legitimacy Minister)
â”œâ”€ âŒ No deception (Truth/ Ethics Minister)
â”œâ”€ âŒ No existential harm (Spirituality Minister)
â””â”€ âŒ No self-contradiction (Identity Validator)

Validation Layers
â”œâ”€ Mode Validator: Catches mode drift
â”œâ”€ Identity Validator: Catches contradictions
â”œâ”€ Conversation Arc: Maintains coherence
â””â”€ Prime Confident: Final approval gate

Graceful Degradation
â”œâ”€ LLM timeout â†’ Fallback response
â”œâ”€ Council error â†’ Direct LLM
â”œâ”€ Memory full â†’ Oldest episodes archived
â””â”€ Thread pool â†’ Graceful shutdown
```

---

## Performance Characteristics

| Component | Latency | Frequency |
|-----------|---------|-----------|
| LLM Call (User) | 3-5s | Every turn |
| LLM Call (Persona) | 5-10s | Every turn |
| Council Convening | 10-30s | WAR/MEETING/DARBAR |
| KIS Ranking | ~100ms | Every decision |
| Feature Extraction | ~1ms | Every decision |
| ML Inference | ~0.5ms | Every decision |
| Memory Write | ~5ms | Every turn |
| Pattern Extraction | ~500ms | Every 100 turns |
| Minister Retraining | ~2s | Every 200 turns |

---

## Scaling Considerations

### Current (Single Node)
- Handles ~100 decisions/hour
- Limited by LLM call speed
- Memory grows ~1KB per turn

### Horizontal Scaling
- Multiple orchestrator instances
- Shared ML model storage
- Distributed episodic memory

### Optimization Opportunities
- LLM call batching
- Vector memory for faster retrieval
- GPU acceleration for ML training
- Caching for repeated queries

---

## Next Steps

ğŸ“„ **Continue Reading:**
- [`03_FILE_REFERENCE.md`](./03_FILE_REFERENCE.md) - Every file explained
- [`04_DATA_FLOW.md`](./04_DATA_FLOW.md) - Data pipelines
- [`05_FLOWCHARTS.md`](./05_FLOWCHARTS.md) - Visual diagrams
