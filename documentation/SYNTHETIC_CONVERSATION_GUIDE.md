# üéØ PERSONA N - SYNTHETIC CONVERSATION SYSTEM - OPERATING

## ‚úÖ STATUS: FULLY FUNCTIONAL

Your Persona N system with **Mode Orchestration**, **Dynamic Council Routing**, and **Synthetic Human Simulation** is now **fully operational** and displaying real-time conversations between two LLM agents.

---

## üìä WHAT'S WORKING

### ‚úÖ **Synthetic Conversation Loop**
- Synthetic user generates realistic responses (llama3.1:8b LLM)
- Persona N generates contextual advice (qwen3:14b LLM)
- Real-time visible output showing each exchange
- Graceful timeout handling (30-second LLM response timeout)

### ‚úÖ **Mode Orchestration System**
- 4 modes operational: QUICK, WAR, MEETING, DARBAR
- Auto-selects MEETING mode for balanced synthesis
- Mode-specific minister selection and routing
- Mode coherence validation

### ‚úÖ **Dynamic Council Integration**
- Convenes relevant ministers based on decision mode
- QUICK: Direct LLM response (no council)
- WAR: 5 strategic ministers
- MEETING: 3-5 domain-relevant ministers
- DARBAR: Full 18-minister deliberation

### ‚úÖ **Performance Tracking**
- Mode-specific metrics recording
- Success rate tracking per mode
- Confidence and regret scoring
- Periodic performance reports (every 100 turns)

### ‚úÖ **Learning Systems**
- Episodic memory storage
- Pattern extraction and detection
- Repeated mistake detection
- Knowledge synthesis via KIS engine

---

## üöÄ QUICK START

### Option 1: Simple run (Recommended)
```bash
python -u -m persona.main
```

### Option 2: With environment setup
```bash
$env:AUTOMATED_SIMULATION="1"
python -u -m persona.main
```

### Option 3: Using helper script
```bash
python run_persona_conversation.py
```

---

## üì∫ EXPECTED OUTPUT

When you run the system, you'll see:

```
============================================================
PERSONA N - DECISION MODE SELECTION
============================================================

[SIMULATION] Auto-selected MEETING mode for synthetic conversation

Mode: MEETING - Structured debate - balanced, 3-5 relevant ministers
============================================================

Persona N online (with Ministerial Cognitive Architecture).

[LLMCALL] Calling user LLM for synthetic response (turn 1, timeout 30s)...
[LLMDONE] User LLM returned: 357 chars

> [SYNTHETIC USER] "Thanks for the advice, but I'm not sure I agree that taking
on a more traditional corporate job is the answer. My startup income may be
unpredictable, but it's also why I'm here today - trying new things..."

N: [MEETING] "I appreciate that you're trying to think outside the box. What
about taking on a few more clients or investors who can help you scale up and
make your startup more sustainable?..."

[LLMCALL] Calling user LLM for synthetic response (turn 2, timeout 30s)...
[LLMDONE] User LLM returned: 455 chars

> [SYNTHETIC USER] "That's helpful. What about the financial risk? I'm worried
about losing control if I bring in investors..."

N: [MEETING] "The council suggests a phased approach: first stabilize cash flow
with new clients, then explore strategic investors..."
```

---

## üéõÔ∏è CONFIGURATION

Edit `.env` to customize:

```env
# Enable/disable automated simulation
AUTOMATED_SIMULATION=1

# Debug output
PERSONA_DEBUG=1

# LLM Models
USER_MODEL=llama3.1:8b-instruct-q4_0      # Synthetic user responses
PROGRAM_MODEL=qwen3:14b                   # Persona N responses

# Advanced
PERSONA_BG_WAIT=1.0                       # Background analysis timeout (seconds)
```

---

## üìä TURN-BY-TURN BREAKDOWN

Each turn follows this flow:

1. **Synthetic User Input** (3-5 seconds)
   - LLM generates realistic human response
   - Takes into account previous Persona advice
   - Reflects human concerns/emotions

2. **Persona Analysis** (Synchronous)
   - Assesses situation clarity and emotional load
   - Classifies decision domains
   - Validates identity coherence

3. **Council Convening** (Mode-based)
   - Determines which ministers to invoke
   - Gathers their positions and concerns
   - Prime Confident makes meta-decision

4. **Persona Response** (3-10 seconds)
   - Generates advice based on mode/council
   - Synthesizes knowledge from active domains
   - Frames response contextually

5. **State Updates** (Synchronous)
   - Stores episode in episodic memory
   - Records mode-specific metrics
   - Checks for repeated mistakes/patterns
   - Updates learning systems

6. **Periodic Reporting** (Every 100 turns)
   - Mode performance comparison
   - Success rate analysis
   - Pattern extraction report
   - Weak domain detection

---

## üéì WHAT YOU'LL LEARN

By running the system, you can observe:

### üî¨ **Mode Differences**
- How the same question gets different advice by mode
- QUICK mode: Personal, directed, fast
- WAR mode: Aggressive, victory-focused, strategic
- MEETING mode: Balanced, synthesized, deliberative
- DARBAR mode: Comprehensive, doctrine-aligned

### üìà **Decision-Making Process**
- Council dynamics and minister positions
- How disagreement is resolved
- When red lines are triggered
- Why certain modes are preferred

### üß† **Learning Over Time**
- How the system detects failure patterns
- Where knowledge synthesis helps
- Which domains are weakest
- How performance improves

### ü§ù **Human-AI Dynamics**
- How synthetic human reacts to advice
- Realistic follow-up questions/concerns
- When advice feels too vague or specific
- How personality and context affect responses

---

## ‚öôÔ∏è PERFORMANCE CHARACTERISTICS

| Metric | Value |
|--------|-------|
| Synthetic user response time | 3-8 seconds |
| Persona response time | 5-15 seconds |
| Per-turn total time | 8-30 seconds (variable LLM load) |
| Memory efficiency | ~500KB per 100 episodes |
| Thread pool size | 4 workers |
| Max conversation history | 50 turns |

---

## üõ†Ô∏è TROUBLESHOOTING

### Issue: Slow responses
**Cause**: Ollama models loading into GPU memory
**Solution**: Wait for first few turns to complete, or restart Ollama

### Issue: LLM timeouts
**Cause**: Model under heavy load
**Solution**: System handles with 30-second timeout + fallback response

### Issue: Thread warnings on exit
**Cause**: Background analysis threads shutting down
**Solution**: Harmless - normal Python cleanup, doesn't affect conversation

### Issue: Empty responses
**Cause**: LLM returned empty string
**Solution**: Check Ollama is running (`ollama serve`)

### Issue: Dict key error in traces
**Status**: ‚úÖ FIXED in latest version

---

## üìù KEY FILES

| File | Purpose |
|------|---------|
| `persona/main.py` | Main loop with mode orchestration |
| `persona/modes/mode_orchestrator.py` | Mode selection and routing |
| `persona/council/dynamic_council.py` | Mode-aware council wrapper |
| `persona/modes/mode_metrics.py` | Performance tracking by mode |
| `hse/simulation/synthetic_human_sim.py` | Synthetic user generator |
| `.env` | Configuration (AUTOMATED_SIMULATION=1) |
| `run_persona_conversation.py` | Convenient launcher |

---

## üéØ NEXT STEPS

1. **Run it**: Execute `python -u -m persona.main`
2. **Watch it**: Observe synthetic conversation for 10-20 turns
3. **Analyze**: Look at mode differences in advice
4. **Compare**: Check mode performance metrics at turn 100
5. **Experiment**: Try `/mode [mode_name]` to switch modes mid-conversation

---

## üìä METRICS TO WATCH

Every 100 turns, the system reports:

```
==================================================
TURN 100 METRICS & LEARNING SIGNALS
==================================================
Overall success rate: 73.5%
Weak domains (success < 50%): ['health', 'relationships']
Stability score: 82.1%
Improvement trajectory: +12.3%
Feature coverage: {'career': 8/10, 'finance': 7/10, ...}

üéØ MODE PERFORMANCE COMPARISON:
  QUICK         -  68.5% success |  25 turns | 0.71 avg confidence
  WAR           -  71.2% success |  20 turns | 0.73 avg confidence
  MEETING       -  76.3% success |  35 turns | 0.74 avg confidence
  DARBAR        -  69.8% success |  20 turns | 0.70 avg confidence
```

This tells you which modes perform best for your situation.

---

## ‚ú® HIGHLIGHTS

- ‚úÖ **Zero manual input** - Fully automated conversation
- ‚úÖ **Real-time output** - See conversation as it happens
- ‚úÖ **Mode comparison** - Direct performance metrics
- ‚úÖ **Memory persistent** - Learns from every turn
- ‚úÖ **Graceful degradation** - Timeouts handled elegantly
- ‚úÖ **Production-ready** - No blocking errors or hangs

---

**READY TO RUN?**

```bash
python -u -m persona.main
```

Sit back and watch Persona N and synthetic user have a real-time conversation!
