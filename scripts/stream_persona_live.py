"""Stream a USER <-> PROGRAM (persona) conversation to the terminal and save to logs.

Usage: run from repo root: python scripts/stream_persona_live.py

This script runs a short automated streaming session (5 turns) where the USER
is generated by a USER_MODEL via the `ollama` CLI and the PROGRAM is the
persona runtime `persona.OllamaRuntime`. Outputs are printed live and appended
to `logs/live_exchange.json`.
"""
import os
import sys
import time
import json
import subprocess
from pathlib import Path

sys.path.insert(0, str(Path(__file__).resolve().parents[1]))

from hse.human_profile import SyntheticHuman, build_user_prompt
from persona.state import CognitiveState
from persona.context import build_system_context
from persona.ollama_runtime import OllamaRuntime

ROOT = Path(__file__).resolve().parents[1]
LOG_FILE = ROOT / "logs" / "live_exchange.json"
LOG_FILE.parent.mkdir(exist_ok=True)

USER_MODEL = os.getenv("USER_MODEL", "huihui_ai/deepseek-r1-abliterated:8b")
PROGRAM_MODEL = os.getenv("PROGRAM_MODEL", "qwen3:14b")

def safe_print(label, s):
    if s is None:
        return
    try:
        safe = s.encode('cp1252', errors='replace').decode('cp1252')
    except Exception:
        safe = s
    print(label + safe)

def call_user_model(prompt: str) -> str:
    p = subprocess.run(["ollama", "run", USER_MODEL], input=prompt.encode('utf-8'), stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    out = p.stdout.decode('utf-8', errors='replace').strip()
    return out

def append_log(entry):
    # Load existing data; accept a dict (wrap into list) or list.
    data = []
    if LOG_FILE.exists():
        try:
            with open(LOG_FILE, 'r', encoding='utf-8') as f:
                existing = json.load(f)
            if isinstance(existing, list):
                data = existing
            elif isinstance(existing, dict):
                data = [existing]
            else:
                data = []
        except Exception:
            data = []
    data.append(entry)
    with open(LOG_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2)

def main(turns=5):
    human = SyntheticHuman(name='Arjun', age=29, profession='Tech founder')
    coverage = {f: 0 for f in ['Quick mode decision','War mode confrontation','Meeting structured planning','DARBAR multi-perspective synthesis']}
    base_user_prompt = build_user_prompt(human, 'career', coverage)

    state = CognitiveState()
    state.mode = 'quick'
    system_context = build_system_context(state)

    persona_llm = OllamaRuntime(speak_model=PROGRAM_MODEL)

    prev_program = None
    for turn in range(1, turns+1):
        safe_print(f"\n--- TURN {turn} — USER (model={USER_MODEL}) ---\n", "")
        user_prompt = base_user_prompt
        if prev_program:
            user_prompt = f"{base_user_prompt}\n\nPrevious program response:\n{prev_program}\n\nRespond as the user (Arjun):"

        user_msg = call_user_model(user_prompt)
        safe_print('', user_msg + '\n')

        safe_print(f"--- TURN {turn} — PROGRAM (persona, model={PROGRAM_MODEL}) ---\n", "")
        program_msg = persona_llm.speak(system_context, user_msg)
        safe_print('', program_msg + '\n')

        entry = {
            'ts': time.time(),
            'turn': turn,
            'user_model': USER_MODEL,
            'program_model': PROGRAM_MODEL,
            'user_msg': user_msg,
            'program_msg': program_msg,
        }
        append_log(entry)

        prev_program = program_msg
        time.sleep(0.5)

    safe_print('\nSaved ', str(LOG_FILE) + '\n')

if __name__ == '__main__':
    try:
        main(turns=5)
    except KeyboardInterrupt:
        print('\nInterrupted by user')
