# ERA System - Environment Configuration Template
# Copy this file to .env and adjust values for your environment
# Generated: February 19, 2026

# =============================================================================
# OLLAMA CONFIGURATION
# =============================================================================

# Ollama server location (default: localhost:11434)
OLLAMA_HOST=http://localhost:11434

# User LLM model (for exploratory, detailed reasoning)
OLLAMA_MODEL_USER=deepseek-r1:8b

# Program LLM model (for structured, systematic responses)
OLLAMA_MODEL_PROGRAM=qwen3:14b

# Alternative models (uncomment to use):
# OLLAMA_MODEL_USER=mistral:7b        # Faster, good quality
# OLLAMA_MODEL_PROGRAM=neural-chat:7b # Chat-optimized
# OLLAMA_MODEL_USER=llama2:13b        # Larger, better reasoning

# Ollama API timeout (seconds)
OLLAMA_TIMEOUT=300

# =============================================================================
# SYSTEM PATHS
# =============================================================================

# ERA root directory
ERA_ROOT=c:\era

# Data storage directory
DATA_ROOT=c:\era\data

# Logs directory
LOG_DIR=c:\era\logs

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Log format: text or json
LOG_FORMAT=text

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================

# Episode storage (episodic memory)
EPISODES_DB=sqlite:///./data/episodes.db

# Alternative: PostgreSQL async
# EPISODES_DB=postgresql://user:password@localhost/era_episodes

# Metrics storage
METRICS_DB=sqlite:///./data/metrics.db

# =============================================================================
# MACHINE LEARNING CONFIGURATION
# =============================================================================

# Batch size for ML training
ML_BATCH_SIZE=32

# Learning rate for judgment prior updates
ML_LEARNING_RATE=0.001

# Number of training epochs
ML_EPOCHS=10

# Feature vector dimensionality
ML_FEATURE_DIM=128

# =============================================================================
# CACHE CONFIGURATION
# =============================================================================

# Cache cleanup age threshold (days)
CACHE_CLEANUP_DAYS=7

# Maximum cache size (MB) before triggering cleanup
CACHE_MAX_SIZE_MB=500

# Enable automatic cache cleanup on startup
CACHE_AUTO_CLEANUP=true

# Cache retention policies (days) - override defaults
# CACHE_ML_DAYS=7
# CACHE_RAG_DAYS=14
# CACHE_CONVERSATIONS_DAYS=30
# CACHE_SESSIONS_DAYS=90

# =============================================================================
# KNOWLEDGE INTEGRATION SYSTEM (KIS)
# =============================================================================

# KIS default domain weight (0.25-1.4)
KIS_DOMAIN_WEIGHT=0.9

# KIS knowledge type weight (0.9-1.1)
KIS_TYPE_WEIGHT=1.0

# KIS memory weight (1.0-8.0)
KIS_MEMORY_WEIGHT=2.0

# KIS context weight (0.85-1.4)
KIS_CONTEXT_WEIGHT=1.0

# KIS goal alignment weight
KIS_GOAL_WEIGHT=0.9

# =============================================================================
# MODE ESCALATION CONFIGURATION
# =============================================================================

# Default starting mode (QUICK, MEETING, WAR, DARBAR)
DEFAULT_MODE=QUICK

# Auto-escalate mode based on turn count
AUTO_ESCALATE_MODE=true

# Turn thresholds for escalation
ESCALATE_TO_MEETING_TURN=3
ESCALATE_TO_WAR_TURN=6
ESCALATE_TO_DARBAR_TURN=9

# =============================================================================
# SESSION MANAGEMENT
# =============================================================================

# Session auto-save interval (turns)
SESSION_AUTO_SAVE=1

# Session satisfaction check (enable satisfaction prompt)
SESSION_CHECK_SATISFACTION=true

# Session consequence tracking (record follow-ups)
SESSION_TRACK_CONSEQUENCES=true

# Session retention (days)
SESSION_RETENTION_DAYS=90

# =============================================================================
# LLM CONVERSATION ENGINE
# =============================================================================

# Default conversation rounds
CONVERSATION_DEFAULT_ROUNDS=5

# Maximum conversation rounds
CONVERSATION_MAX_ROUNDS=10

# Conversation auto-save
CONVERSATION_AUTO_SAVE=true

# Conversation storage format (json or yaml)
CONVERSATION_FORMAT=json

# =============================================================================
# PERSONALITY & DRIFT
# =============================================================================

# Enable personality drift tracking
PERSONALITY_DRIFT_ENABLED=true

# Personality drift sensitivity (0.0-1.0)
PERSONALITY_DRIFT_SENSITIVITY=0.5

# =============================================================================
# ANALYTICS & METRICS
# =============================================================================

# Enable performance dashboard
ANALYTICS_ENABLED=true

# Dashboard refresh interval (seconds)
ANALYTICS_REFRESH=60

# Track decision quality metrics
TRACK_DECISION_QUALITY=true

# Track minister contributions
TRACK_MINISTER_CONTRIBUTIONS=true

# =============================================================================
# HUMAN SIMULATION ENGINE (HSE)
# =============================================================================

# Enable synthetic human generation
HSE_ENABLED=true

# Number of synthetic humans to generate
HSE_POPULATION_SIZE=5

# Stress level range for synthetic humans (0.0-1.0)
HSE_STRESS_MIN=0.3
HSE_STRESS_MAX=0.8

# =============================================================================
# INGESTION PIPELINE
# =============================================================================

# Books directory (PDFs for knowledge ingestion)
BOOKS_DIR=c:\era\data\books

# Processed data output directory
INGESTION_OUTPUT_DIR=c:\era\data\ingestion

# Batch size for concurrent ingest operations
INGESTION_BATCH_SIZE=5

# =============================================================================
# FEATURE FLAGS
# =============================================================================

# Enable KIS knowledge scoring
FEATURE_KIS_ENABLED=true

# Enable ML judgment learning
FEATURE_ML_LEARNING_ENABLED=true

# Enable session persistence
FEATURE_SESSION_PERSISTENCE=true

# Enable conversation persistence
FEATURE_CONVERSATION_PERSISTENCE=true

# Enable cache management
FEATURE_CACHE_MANAGEMENT=true

# Enable personality drift tracking
FEATURE_PERSONALITY_DRIFT=true

# =============================================================================
# ADVANCED CONFIGURATION
# =============================================================================

# Request timeout (seconds)
REQUEST_TIMEOUT=60

# Max retries for failed requests
MAX_RETRIES=3

# Retry backoff multiplier (exponential)
RETRY_BACKOFF=2.0

# Enable debug mode (verbose logging)
DEBUG_MODE=false

# =============================================================================
# DEPRECATED / LEGACY
# =============================================================================

# These options are kept for backwards compatibility but may be removed
# LEGACY_RAG_STORAGE=c:\era\rag_storage
# LEGACY_EPISODIC_MEMORY=c:\era\memory

# =============================================================================
# NOTES
# =============================================================================

# 1. Copy this file to .env in ERA root directory
# 2. Adjust values for your environment
# 3. Some options require ERA restart to take effect
# 4. Removed options use sensible defaults (see documentation)
# 5. For questions on any setting, check DEPENDENCIES.md or SYSTEM_ARCHITECTURE.md

# Default values are in:
# - persona/modes/ (mode defaults)
# - ml/ (ML defaults)
# - hse/ (simulation defaults)

# =============================================================================
